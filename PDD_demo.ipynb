{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physical Distancing Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries - Make sure opencv, tensorflow and scipy is installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "import argparse\n",
    "import itertools\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Person Detection"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Input - Tensorflow object detection model(.tflite)\n",
    "Optional Input(s) - person detection thresold value\n",
    "                    tensor input shape - current model uses 320x320 image\n",
    "Output - Prediction dictionary with detection boxes, confidence scores and object classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person_detection(object):\n",
    "    \n",
    "    def __init__(self, model_name, min_threshold=0.40, input_shape=(320,320)):\n",
    "        \n",
    "        #initialize threshold values, interpreters and tensors\n",
    "        self.min_score_threshold = min_threshold\n",
    "        self.model = os.path.join('models', model_name)\n",
    "        self.interpreter = tf.lite.Interpreter(model_path=self.model)\n",
    "        self.input_tensor = self.interpreter.get_input_details()\n",
    "        self.output_tensor = self.interpreter.get_output_details()\n",
    "        self.interpreter.allocate_tensors()\n",
    "\n",
    "    def predict(self, frame):\n",
    "        \n",
    "        # return the predictions for each frame\n",
    "        # prediction contains the bounding box coordinates, object classes and scores\n",
    "        \n",
    "        if self.input_tensor[0]['dtype'] == np.float32:\n",
    "            dtype_model = tf.float32\n",
    "        else:\n",
    "            dtype_model = tf.uint8\n",
    "        input_tensor = tf.convert_to_tensor(frame, dtype=dtype_model)\n",
    "        input_tensor = input_tensor[tf.newaxis, ...]\n",
    "        \n",
    "        self.interpreter.set_tensor(self.input_tensor[0]['index'], input_tensor)\n",
    "        self.interpreter.invoke()\n",
    "        \n",
    "        det_box = tf.convert_to_tensor(self.interpreter.get_tensor(self.output_tensor[0]['index']))\n",
    "        det_class = tf.convert_to_tensor(self.interpreter.get_tensor(self.output_tensor[1]['index']))\n",
    "        det_score = tf.convert_to_tensor(self.interpreter.get_tensor(self.output_tensor[2]['index']))\n",
    "        \n",
    "        # convert tensor object to numpy array\n",
    "        det_class = tf.squeeze(det_class, axis=[0]).numpy().astype(np.int64) + 1\n",
    "        det_box = tf.squeeze(det_box, axis=[0]).numpy()\n",
    "        det_score = tf.squeeze(det_score, axis=[0]).numpy()\n",
    "        \n",
    "        return{\n",
    "            'det_boxes': det_box,\n",
    "            'det_classes': det_class,\n",
    "            'det_scores': det_score\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Physical distancing detection function which uses euclidean distance between the centroids of each person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def physical_distance_detection(prediction, dist_threshold, frame):\n",
    "    \n",
    "    detection = [False] * len(prediction['det_boxes'])\n",
    "    centroids = []\n",
    "    red_color = (0,0,255)\n",
    "    \n",
    "    # calculate centroid value of each bunding box / person\n",
    "    for boxes in prediction['det_boxes']:\n",
    "        centroids.append(((boxes[1] + boxes[3])/2, (boxes[0]+ boxes[2])/2))\n",
    "        \n",
    "    # calculate the euclidean distance between each centroid\n",
    "    for ((x,x1),( y,y1)) in itertools.combinations(enumerate(centroids), 2):\n",
    "        if detection[x] and detection[y]:\n",
    "            continue\n",
    "\n",
    "        if cdist([x1],[y1], 'euclidean')[0][0] < dist_threshold:\n",
    "                detection[x] = True\n",
    "                detection[y] = True\n",
    "                frame = cv.arrowedLine(frame, (int(x1[0]),int(x1[1])), (int(y1[0]),int(y1[1])), red_color,6)\n",
    "\n",
    "    return detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Up code to remove unwanted detections - like low confidence scores, objects other than person and object with bounding box too large considering the frame and camera view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(prediction, image_w, image_h):\n",
    "    \n",
    "    delete_ids = []\n",
    "\n",
    "    for i in range(len(prediction['det_classes'])):\n",
    "        \n",
    "        #select only person object\n",
    "        if prediction['det_classes'][i] != 1:\n",
    "            delete_ids.append(i)\n",
    "        \n",
    "        # select only objects with scores greater than threshold\n",
    "        if prediction['det_scores'][i] < 0.5:\n",
    "            delete_ids.append(i)\n",
    "        \n",
    "        x_min, y_min = int(prediction['det_boxes'][i][1] * image_w), int(prediction['det_boxes'][i][0] * image_h)\n",
    "        x_max, y_max = int(prediction['det_boxes'][i][3] * image_w), int(prediction['det_boxes'][i][2] * image_h)\n",
    "        prediction['det_boxes'][i] =  [y_min, x_min, y_max, x_max]\n",
    "        \n",
    "        if (x_max - x_min > image_w/3) or (y_max - y_min > image_h /2):\n",
    "            delete_ids.append(i)\n",
    "            \n",
    "    cleaned_list = list(dict.fromkeys(delete_ids))\n",
    "    prediction['det_classes'] = np.delete(prediction['det_classes'], cleaned_list, axis=0)\n",
    "    prediction['det_boxes'] = np.delete(prediction['det_boxes'], cleaned_list, axis=0)\n",
    "    prediction['det_scores'] = np.delete(prediction['det_scores'], cleaned_list, axis=0)\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw bounding box rectangles around detected persons using open cv functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rect(image, box, image_w, image_h, detection=False):\n",
    "    \n",
    "    red_color = (0, 0 , 255)\n",
    "    green_color = (0, 255, 0)\n",
    "    \n",
    "    y_min = int(max(1, box[0]))\n",
    "    x_min = int(max(1, box[1]))\n",
    "    y_max = int(min(image_h, box[2]))\n",
    "    x_max = int(min(image_w, box[3]))\n",
    "    \n",
    "    # draw a rectangle on the image\n",
    "    if detection:\n",
    "        cv.rectangle(image, (x_min, y_min), (x_max, y_max), red_color, 2)\n",
    "    else:\n",
    "        cv.rectangle(image, (x_min, y_min), (x_max, y_max), green_color, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entry point\n",
    "Can be executed as a script with 3 optional arguments\n",
    "args [-d] - predefined threshold for physical distancing (in pixel, depending on the video or stream source and fov)\n",
    "     [-i] - input video filename with path\n",
    "     [-o] - output video filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    parser.add_argument('-d', type=int, required=False, dest='dist', default=150, \\\n",
    "                        help=\"physical distancing threshold distance in pixel\")\n",
    "    parser.add_argument('-i', type=str, required=False, dest='video', \\\n",
    "                        default='PDD_demo.avi', help=\"input video file name\")\n",
    "    parser.add_argument('-o', type=str, required=False, dest='op', \\\n",
    "                        default='PDD_ouput_demo.avi', help=\"output video file name\")\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    \n",
    "    dist_threshold = args.dist\n",
    "    input_video = args.video\n",
    "\n",
    "    # load the input Video\n",
    "    vid = cv.VideoCapture(input_video)\n",
    "    \n",
    "    # Calculate the height and width of the stream\n",
    "    image_w = int(vid.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "    image_h = int(vid.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # Storing the output to a avi video\n",
    "    fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv.VideoWriter(args.op, fourcc, 24, (image_w,image_h), True)\n",
    "    \n",
    "    # Load the detection model with threshold\n",
    "    people_model = Person_detection('model.tflite',0.5)\n",
    "\n",
    "    while(vid.isOpened()):\n",
    "        \n",
    "        ret_val, frame = vid.read()\n",
    "        \n",
    "        if frame is None or frame.size == 0:\n",
    "            break\n",
    "        else:\n",
    "            # Resize the image to expected tensor shape for the loaded model\n",
    "            prediction = people_model.predict(cv.resize(frame, (320,320)))\n",
    "        \n",
    "            # Cleanup non person and weak predictions\n",
    "            person_prediction = cleanup(prediction, image_w, image_h)\n",
    "        \n",
    "            # Run the physical distance detector for each person\n",
    "            # dist_threshold is the minimum distance between persons to consider breach\n",
    "            detection = physical_distance_detection(person_prediction, dist_threshold, frame)\n",
    "\n",
    "            # Draw the rectangle bounding boxes\n",
    "            for i in range(len(person_prediction['det_boxes'])):\n",
    "                draw_rect(frame, person_prediction['det_boxes'][i], image_w, image_h, detection[i])\n",
    "\n",
    "            # Display the frame\n",
    "            cv.imshow('PDD_DEMO', frame)\n",
    "            out.write(frame)\n",
    "            if cv.waitKey(1) == 27 or ret_val is False:\n",
    "                break\n",
    "        \n",
    "    cv.destroyWindow('PDD_DEMO')\n",
    "    if out is not None:\n",
    "        out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
